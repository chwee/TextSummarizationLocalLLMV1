{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain with LLAMA.CPP Quantized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install python module\n",
    "\n",
    "- pip install langchain\n",
    "- pip install -U langchain-community\n",
    "- pip install streamlit\n",
    "- pip install pypdf2\n",
    "- pip install pypdf\n",
    "- pip install tiktoken\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install torch\n",
    "For GPU installation:\n",
    "\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "\n",
    "For CPU installation:\n",
    "\n",
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install llama.cpp llama-cpp-python\n",
    "\n",
    "For GPU installation:\n",
    "\n",
    "set CMAKE_ARGS=-DLLAMA_BUILD=on\n",
    "\n",
    "Set GGML_CUDA=on\n",
    "\n",
    "pip install llama-cpp-python==0.1.64 --force-reinstall --upgrade --no-cache-dir\n",
    "\n",
    "\n",
    "For CPU installation:\n",
    "\n",
    "pip install llama-cpp-python==0.1.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set bindings for LLAMA.CPP quantized model and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "n_gpu_layers = 0  # 0-cpu , set a number eg 32- GPU layer\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/llm/mistral-7b-instruct-v0.1.Q6_K.gguf\"\n",
    "\n",
    "llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        temperature=0,\n",
    "        max_tokens=8000,\n",
    "        top_p=1,\n",
    "        # callback_manager=callback_manager,\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_batch=512,\n",
    "        n_ctx=8000,\n",
    "        stop=[\"[INST]\"],\n",
    "        verbose=False,\n",
    "        streaming=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA: Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to learn and make predictions or decisions. These networks are designed to mimic the structure and function of the human brain, allowing them to process large amounts of complex data and identify patterns or features that may be difficult for humans to detect. Deep learning has been used in a variety of applications, including image recognition, natural language processing, speech recognition, and autonomous driving.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "evaluate the summary text against it's original text based on the following criteria:\n",
    "1.Coverage of details from the original text.\n",
    "2.Factual alignment between the original text and summary.\n",
    "Give each result in the grading 1-10, where 1 is the lowest and 10 is the highest.\n",
    "Provide some reasoning for you grading.\n",
    "\n",
    "original text:\n",
    "large language models (LLMs) powering chatbots like ChatGPT help our company \n",
    "achieve its vision? Suddenly, hundreds of millions of users were having \n",
    "natural-sounding conversations with ChatGPT about anything and everything, \n",
    "including their emotions and mental health. Could this new breed of LLMs provide a \n",
    "viable generative-AI alternative to the rules-based approach Woebot has always \n",
    "used? The AI team at Woebot Health, including the authors of this article, were \n",
    "asked to find out.\n",
    "Woebot, a mental-health chatbot, deploys concepts from cognitive behavioral therapy\n",
    "to help users. This demo shows how users interact with Woebot using a combination \n",
    "of multiple-choice responses and free-written text.\n",
    "The Origin and Design of Woebot\n",
    "Woebot got its start when the clinical research psychologist Alison Darcy, with \n",
    "support from the AI pioneer Andrew Ng, led the build of a prototype intended as an \n",
    "emotional support tool for young people. Darcy and another member of the founding \n",
    "team, Pierre Rappolt, took inspiration from video games as they looked for ways for\n",
    "the tool to deliver elements of CBT. Many of their prototypes contained interactive\n",
    "fiction elements, which then led Darcy to the chatbot paradigm. The first version \n",
    "of the chatbot was studied in a randomized control trial that offered mental-health\n",
    "support to college students. Based on the results, Darcy raised US $8 million from \n",
    "New Enterprise Associates and Andrew Ng’s AI Fund.\n",
    "The Woebot app is intended to be an adjunct to human support, not a replacement for\n",
    "it. It was built according to a set of principles that we call Woebot’s core \n",
    "beliefs, which were shared on the day it launched. These tenets express a strong \n",
    "faith in humanity and in each person’s ability to change, choose, and grow. The app\n",
    "does not diagnose, it does not give medical advice, and it does not force its users\n",
    "into conversations. Instead, the app follows a Buddhist principle that’s prevalent \n",
    "in CBT of “sitting with open hands”—it extends invitations that the user can choose\n",
    "to accept, and it encourages process over results. Woebot facilitates a user’s \n",
    "growth by asking the right questions at optimal moments, and by engaging in a type \n",
    "of interactive self-help that can happen anywhere, anytime.\n",
    "A Convenient Companion\n",
    "Users interact with Woebot either by choosing prewritten responses or by typing in \n",
    "whatever text they’d like, which Woebot parses using AI techniques. Woebot deploys \n",
    "concepts from cognitive behavioral therapy to help users change their thought \n",
    "patterns. Here, it first asks a user to write down negative thoughts, then explains\n",
    "the cognitive distortions at work. Finally, Woebot invites the user to recast a \n",
    "negative statement in a positive way. (Not all exchanges are shown.)\n",
    "These core beliefs strongly influenced both Woebot’s engineering architecture and \n",
    "its product-development process. Careful conversational design is crucial for \n",
    "ensuring that interactions conform to our principles. Test runs through a \n",
    "conversation are read aloud in “table reads,” and then revised to better express \n",
    "the core beliefs and flow more naturally. The user side of the conversation is a \n",
    "mix of multiple-choice responses and “free text,” or places where users can write \n",
    "whatever they wish.\n",
    "Building an app that supports human health is a high-stakes endeavor, and we’ve \n",
    "taken extra care to adopt the best software-development practices. From the start, \n",
    "enabling content creators and clinicians to collaborate on product development \n",
    "required custom tools. An initial system using Google Sheets quickly became \n",
    "unscalable, and the engineering team replaced it with a proprietary Web-based \n",
    "“conversational management system” written in the JavaScript library React.\n",
    "Within the system, members of the writing team can create content, play back that \n",
    "content in a preview mode, define routes between content modules, and find places \n",
    "for users to enter free text, which our AI system then parses. The result is a \n",
    "large rules-based tree of branching conversational routes, all organized within \n",
    "modules such as “social skills training” and “challenging thoughts.” These modules \n",
    "are translated from psychological mechanisms within CBT and other evidence-based \n",
    "techniques.\n",
    "How Woebot Uses AI\n",
    "While everything Woebot says is written by humans, NLP techniques are used to help \n",
    "understand the feelings and problems users are facing; then Woebot can offer the \n",
    "most appropriate modules from its deep bank of content. When users enter free text \n",
    "about their thoughts and feelings, we use NLP to parse these text inputs and route \n",
    "the user to the best response.\n",
    "In Woebot’s early days, the engineering team used regular expressions, or \n",
    "“regexes,” to understand the intent behind these text inputs. Regexes are a \n",
    "text-processing method that relies on pattern matching within sequences of \n",
    "characters. Woebot’s regexes were quite complicated in some cases, and were used \n",
    "for everything from parsing simple yes/no responses to learning a user’s preferred \n",
    "nickname.\n",
    "Later in Woebot’s development, the AI team replaced regexes with classifiers \n",
    "trained with supervised learning. The process for creating AI classifiers that \n",
    "comply with regulatory standards was involved—each classifier required months of \n",
    "effort. Typically, a team of internal-data labelers and content creators reviewed \n",
    "examples of user messages (with all personally identifiable information stripped \n",
    "out) taken from a specific point in the conversation. Once the data was placed into\n",
    "categories and labeled, classifiers were trained that could take new input text and\n",
    "place it into one of the existing categories.\n",
    "This process was repeated many times, with the classifier repeatedly evaluated \n",
    "against a test dataset until its performance satisfied us. As a final step, the \n",
    "conversational-management system was updated to “call” these AI classifiers \n",
    "(essentially activating them) and then to route the user to the most appropriate \n",
    "content. For example, if a user wrote that he was feeling angry because he got in a\n",
    "fight with his mom, the system would classify this response as a relationship \n",
    "problem.\n",
    "The technology behind these classifiers is constantly evolving. In the early days, \n",
    "the team used an open-source library for text classification called fastText, \n",
    "sometimes in combination with regular expressions. As AI continued to advance and \n",
    "new models became available, the team was able to train new models on the same \n",
    "labeled data for improvements in both accuracy and recall. For example, when the \n",
    "early transformer model BERT was released in October 2018, the team rigorously \n",
    "evaluated its performance against the fastText version. BERT was superior in both \n",
    "precision and recall for our use cases, and so the team replaced all fastText \n",
    "classifiers with BERT and launched the new models in January 2019. We immediately \n",
    "saw improvements in classification accuracy across the models.\n",
    "An illustration of a robot cheering.EDDIE GUY\n",
    "Woebot and Large Language Models\n",
    "When ChatGPT was released in November 2022, Woebot was more than 5 years old. The \n",
    "AI team faced the question of whether LLMs like ChatGPT could be used to meet \n",
    "Woebot’s design goals and enhance users’ experiences, putting them on a path to \n",
    "better mental health.\n",
    "We were excited by the possibilities, because ChatGPT could carry on fluid and \n",
    "complex conversations about millions of topics, far more than we could ever include\n",
    "in a decision tree. However, we had also heard about troubling examples of chatbots\n",
    "providing responses that were decidedly not supportive, including advice on how to \n",
    "maintain and hide an eating disorder and guidance on methods of self-harm. In one \n",
    "tragic case in Belgium, a grieving widow accused a chatbot of being responsible for\n",
    "her husband’s suicide.\n",
    "The first thing we did was try out ChatGPT ourselves, and we quickly became experts\n",
    "in prompt engineering. For example, we prompted ChatGPT to be supportive and played\n",
    "the roles of different types of users to explore the system’s strengths and \n",
    "shortcomings. We described how we were feeling, explained some problems we were \n",
    "facing, and even explicitly asked for help with depression or anxiety.\n",
    "A few things stood out. First, ChatGPT quickly told us we needed to talk to someone\n",
    "else—a therapist or doctor. ChatGPT isn’t intended for medical use, so this default\n",
    "response was a sensible design decision by the chatbot’s makers. But it wasn’t very\n",
    "satisfying to constantly have our conversation aborted. Second, ChatGPT’s responses\n",
    "were often bulleted lists of encyclopedia-style answers. For example, it would list\n",
    "six actions that could be helpful for depression. We found that these lists of \n",
    "items told the user what to do but didn’t explain how to take these steps. Third, \n",
    "in general, the conversations ended quickly and did not allow a user to engage in \n",
    "the psychological processes of change.\n",
    "It was clear to our team that an off-the-shelf LLM would not deliver the \n",
    "psychological experiences we were after. LLMs are based on reward models that value\n",
    "the delivery of correct answers; they aren’t given incentives to guide a user \n",
    "through the process of discovering those results themselves. Instead of “sitting \n",
    "with open hands,” the models make assumptions about what the user is saying to \n",
    "deliver a response with the highest assigned reward.\n",
    "We had to decide whether generative AI could make Woebot a better tool, or whether \n",
    "the technology was too dangerous to incorporate into our product.\n",
    "To see if LLMs could be used within a mental-health context, we investigated ways \n",
    "of expanding our proprietary conversational-management system. We looked into \n",
    "frameworks and open-source techniques for managing prompts and prompt \n",
    "chains—sequences of prompts that ask an LLM to achieve a task through multiple \n",
    "subtasks. In January of 2023, a platform called LangChain was gaining in popularity\n",
    "and offered techniques for calling multiple LLMs and managing prompt chains. \n",
    "However, LangChain lacked some features that we knew we needed: It didn’t provide a\n",
    "visual user interface like our proprietary system, and it didn’t provide a way to \n",
    "safeguard the interactions with the LLM. We needed a way to protect Woebot users \n",
    "from the common pitfalls of LLMs, including hallucinations (where the LLM says \n",
    "things that are plausible but untrue) and simply straying off topic.\n",
    "Ultimately, we decided to expand our platform by implementing our own LLM \n",
    "prompt-execution engine, which gave us the ability to inject LLMs into certain \n",
    "parts of our existing rules-based system. The engine allows us to support concepts \n",
    "such as prompt chains while also providing integration with our existing \n",
    "conversational routing system and rules. As we developed the engine, we were \n",
    "fortunate to be invited into the beta programs of many new LLMs. Today, our \n",
    "prompt-execution engine can call more than a dozen different LLM models, including \n",
    "variously sized OpenAI models, Microsoft Azure versions of OpenAI models, \n",
    "Anthropic’s Claude, Google Bard (now Gemini), and open-source models running on the\n",
    "Amazon Bedrock platform, such as Meta’s Llama 2. We use this engine exclusively for\n",
    "exploratory research that’s been approved by an institutional review board, or IRB.\n",
    "It took us about three months to develop the infrastructure and tooling support for\n",
    "LLMs. Our platform allows us to package features into different products and \n",
    "experiments, which in turn lets us maintain control over software versions and \n",
    "manage our research efforts while ensuring that our commercially deployed products \n",
    "are unaffected. We’re not using LLMs in any of our products; the LLM-enabled \n",
    "features can be used only in a version of Woebot for exploratory studies.\n",
    "A Trial for an LLM-Augmented Woebot\n",
    "We had some false starts in our development process. We first tried creating an \n",
    "experimental chatbot that was almost entirely powered by generative AI; that is, \n",
    "the chatbot directly used the text responses from the LLM. But we ran into a couple\n",
    "of problems. The first issue was that the LLMs were eager to demonstrate how smart \n",
    "and helpful they are! This eagerness was not always a strength, as it interfered \n",
    "with the user’s own process.\n",
    "For example, the user might be doing a thought-challenging exercise, a common tool \n",
    "in CBT. If the user says, “I’m a bad mom,” a good next step in the exercise could \n",
    "be to ask if the user’s thought is an example of “labeling,” a cognitive distortion\n",
    "where we assign a negative label to ourselves or others. But LLMs were quick to \n",
    "skip ahead and demonstrate how to reframe this thought, saying something like “A \n",
    "kinder way to put this would be, ‘I don’t always make the best choices, but I love \n",
    "my child.’” CBT exercises like thought challenging are most helpful when the person\n",
    "does the work themselves, coming to their own conclusions and gradually changing \n",
    "their patterns of thinking.\n",
    "A second difficulty with LLMs was in style matching. While social media is rife \n",
    "with examples of LLMs responding in a Shakespearean sonnet or a poem in the style \n",
    "of Dr. Seuss, this format flexibility didn’t extend to Woebot’s style. Woebot has a\n",
    "warm tone that has been refined for years by conversational designers and clinical \n",
    "experts. But even with careful instructions and prompts that included examples of \n",
    "Woebot’s tone, LLMs produced responses that didn’t “sound like Woebot,” maybe \n",
    "because a touch of humor was missing, or because the language wasn’t simple and \n",
    "clear.\n",
    "The LLM-augmented Woebot was well-behaved, refusing to take inappropriate actions \n",
    "like diagnosing or offering medical advice.\n",
    "However, LLMs truly shone on an emotional level. When coaxing someone to talk about\n",
    "their joys or challenges, LLMs crafted personalized responses that made people feel\n",
    "understood. Without generative AI, it’s impossible to respond in a novel way to \n",
    "every different situation, and the conversation feels predictably “robotic.”\n",
    "We ultimately built an experimental chatbot that possessed a hybrid of generative \n",
    "AI and traditional NLP-based capabilities. In July 2023 we registered an \n",
    "IRB-approved clinical study to explore the potential of this LLM-Woebot hybrid, \n",
    "looking at satisfaction as well as exploratory outcomes like symptom changes and \n",
    "attitudes toward AI. We feel it’s important to study LLMs within controlled \n",
    "clinical studies due to their scientific rigor and safety protocols, such as \n",
    "adverse event monitoring. Our Build study included U.S. adults above the age of 18 \n",
    "who were fluent in English and who had neither a recent suicide attempt nor current\n",
    "suicidal ideation. The double-blind structure assigned one group of participants \n",
    "the LLM-augmented Woebot while a control group got the standard version; we then \n",
    "assessed user satisfaction after two weeks.\n",
    "We built technical safeguards into the experimental Woebot to ensure that it \n",
    "wouldn’t say anything to users that was distressing or counter to the process. The \n",
    "safeguards tackled the problem on multiple levels. First, we used what engineers \n",
    "consider “best in class” LLMs that are less likely to produce hallucinations or \n",
    "offensive language. Second, our architecture included different validation steps \n",
    "surrounding the LLM; for example, we ensured that Woebot wouldn’t give an \n",
    "LLM-generated response to an off-topic statement or a mention of suicidal ideation \n",
    "(in that case, Woebot provided the phone number for a hotline). Finally, we wrapped\n",
    "users’ statements in our own careful prompts to elicit appropriate responses from \n",
    "the LLM, which Woebot would then convey to users. These prompts included both \n",
    "direct instructions such as “don’t provide medical advice” as well as examples of \n",
    "appropriate responses in challenging situations.\n",
    "While this initial study was short—two weeks isn’t much time when it comes to \n",
    "psychotherapy—the results were encouraging. We found that users in the experimental\n",
    "and control groups expressed about equal satisfaction with Woebot, and both groups \n",
    "had fewer self-reported symptoms. What’s more, the LLM-augmented chatbot was \n",
    "well-behaved, refusing to take inappropriate actions like diagnosing or offering \n",
    "medical advice. It consistently responded appropriately when confronted with \n",
    "difficult topics like body image issues or substance use, with responses that \n",
    "provided empathy without endorsing maladaptive behaviors. With participant consent,\n",
    "we reviewed every transcript in its entirety and found no concerning LLM-generated \n",
    "utterances—no evidence that the LLM hallucinated or drifted off-topic in a \n",
    "problematic way. What’s more, users reported no device-related adverse events.\n",
    "This study was just the first step in our journey to explore what’s possible for \n",
    "future versions of Woebot, and its results have emboldened us to continue testing \n",
    "LLMs in carefully controlled studies. We know from our prior research that Woebot \n",
    "users feel a bond with our bot. We’re excited about LLMs’ potential to add more \n",
    "empathy and personalization, and we think it’s possible to avoid the \n",
    "sometimes-scary pitfalls related to unfettered LLM chatbots.\n",
    "We believe strongly that continued progress within the LLM research community will,\n",
    "over time, transform the way people interact with digital tools like Woebot. Our \n",
    "mission hasn’t changed: We’re committed to creating a world-class solution that \n",
    "helps people along their mental-health journeys. For anyone who wants to talk, we \n",
    "want the best possible version of Woebot to be there for them\n",
    "\n",
    "summary:\n",
    "Woebot is an AI-powered chatbot designed for on-demand mental health support. The company was launched in 2017 and has since become one of the most popular platforms for mental health support. Woebot uses natural language processing (NLP) to understand users' written texts and respond appropriately, with a focus on evidence-based conversations inspired by cognitive behavioral therapy (CBT). Woebot is not a generative AI chatbot like ChatGPT but relies on a rules-based engine.\n",
    "The company has undergone rigorous testing and development practices to ensure it adheres to its core beliefs and provides effective mental health support. In 2019, Woebot launched new models that improved classification accuracy across all models, including BERT. When ChatGPT was released in November 2022, Woebot's AI team evaluated the performance of LLMs like ChatGPT and found them to be superior in both precision and recall. They replaced all fastText classifiers with BERT and saw improvements in classification accuracy across models.\n",
    "In January 2023, Woebot launched a version augmented by LLMs and participated in a clinical study that found users felt equally satisfied with the experimental and control groups, had fewer self-reported symptoms, and were well-behaved, refusing to take inappropriate actions like diagnosing or offering medical advice. The LLM-augmented chatbot provided empathetic responses without endorsing maladaptive behaviors, and there were no concerning LLM-generated utterances, device-related adverse events, or evidence of the LLM hallucinating or drifting off-topic in a problematic way.\n",
    "Woebot's mission is to create a world-class solution that helps people along their mental health journeys, and the best possible version of Woebot is always available for anyone who wants to talk. The company aims to avoid the pitfalls associated with unregulated LLM chatbots and continues testing LLMs in controlled studies.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "evaluate the summary text against it's original text based on the following criteria:\n",
    "    1.Coverage of details from the original text.\n",
    "    2.Factual alignment between the original text and summary.\n",
    "For each criteria above give a grading 1-10, where 1 is the lowest and 10 is the highest.\n",
    "Provide some reasoning for you grading.\n",
    "\n",
    "original text:\n",
    "large language models (LLMs) powering chatbots like ChatGPT help our company \n",
    "achieve its vision? Suddenly, hundreds of millions of users were having \n",
    "natural-sounding conversations with ChatGPT about anything and everything, \n",
    "including their emotions and mental health. Could this new breed of LLMs provide a \n",
    "viable generative-AI alternative to the rules-based approach Woebot has always \n",
    "used? The AI team at Woebot Health, including the authors of this article, were \n",
    "asked to find out.\n",
    "Woebot, a mental-health chatbot, deploys concepts from cognitive behavioral therapy\n",
    "to help users. This demo shows how users interact with Woebot using a combination \n",
    "of multiple-choice responses and free-written text.\n",
    "The Origin and Design of Woebot\n",
    "Woebot got its start when the clinical research psychologist Alison Darcy, with \n",
    "support from the AI pioneer Andrew Ng, led the build of a prototype intended as an \n",
    "emotional support tool for young people. Darcy and another member of the founding \n",
    "team, Pierre Rappolt, took inspiration from video games as they looked for ways for\n",
    "the tool to deliver elements of CBT. Many of their prototypes contained interactive\n",
    "fiction elements, which then led Darcy to the chatbot paradigm. The first version \n",
    "of the chatbot was studied in a randomized control trial that offered mental-health\n",
    "support to college students. Based on the results, Darcy raised US $8 million from \n",
    "New Enterprise Associates and Andrew Ng’s AI Fund.\n",
    "The Woebot app is intended to be an adjunct to human support, not a replacement for\n",
    "it. It was built according to a set of principles that we call Woebot’s core \n",
    "beliefs, which were shared on the day it launched. These tenets express a strong \n",
    "faith in humanity and in each person’s ability to change, choose, and grow. The app\n",
    "does not diagnose, it does not give medical advice, and it does not force its users\n",
    "into conversations. Instead, the app follows a Buddhist principle that’s prevalent \n",
    "in CBT of “sitting with open hands”—it extends invitations that the user can choose\n",
    "to accept, and it encourages process over results. Woebot facilitates a user’s \n",
    "growth by asking the right questions at optimal moments, and by engaging in a type \n",
    "of interactive self-help that can happen anywhere, anytime.\n",
    "A Convenient Companion\n",
    "Users interact with Woebot either by choosing prewritten responses or by typing in \n",
    "whatever text they’d like, which Woebot parses using AI techniques. Woebot deploys \n",
    "concepts from cognitive behavioral therapy to help users change their thought \n",
    "patterns. Here, it first asks a user to write down negative thoughts, then explains\n",
    "the cognitive distortions at work. Finally, Woebot invites the user to recast a \n",
    "negative statement in a positive way. (Not all exchanges are shown.)\n",
    "These core beliefs strongly influenced both Woebot’s engineering architecture and \n",
    "its product-development process. Careful conversational design is crucial for \n",
    "ensuring that interactions conform to our principles. Test runs through a \n",
    "conversation are read aloud in “table reads,” and then revised to better express \n",
    "the core beliefs and flow more naturally. The user side of the conversation is a \n",
    "mix of multiple-choice responses and “free text,” or places where users can write \n",
    "whatever they wish.\n",
    "Building an app that supports human health is a high-stakes endeavor, and we’ve \n",
    "taken extra care to adopt the best software-development practices. From the start, \n",
    "enabling content creators and clinicians to collaborate on product development \n",
    "required custom tools. An initial system using Google Sheets quickly became \n",
    "unscalable, and the engineering team replaced it with a proprietary Web-based \n",
    "“conversational management system” written in the JavaScript library React.\n",
    "Within the system, members of the writing team can create content, play back that \n",
    "content in a preview mode, define routes between content modules, and find places \n",
    "for users to enter free text, which our AI system then parses. The result is a \n",
    "large rules-based tree of branching conversational routes, all organized within \n",
    "modules such as “social skills training” and “challenging thoughts.” These modules \n",
    "are translated from psychological mechanisms within CBT and other evidence-based \n",
    "techniques.\n",
    "How Woebot Uses AI\n",
    "While everything Woebot says is written by humans, NLP techniques are used to help \n",
    "understand the feelings and problems users are facing; then Woebot can offer the \n",
    "most appropriate modules from its deep bank of content. When users enter free text \n",
    "about their thoughts and feelings, we use NLP to parse these text inputs and route \n",
    "the user to the best response.\n",
    "In Woebot’s early days, the engineering team used regular expressions, or \n",
    "“regexes,” to understand the intent behind these text inputs. Regexes are a \n",
    "text-processing method that relies on pattern matching within sequences of \n",
    "characters. Woebot’s regexes were quite complicated in some cases, and were used \n",
    "for everything from parsing simple yes/no responses to learning a user’s preferred \n",
    "nickname.\n",
    "Later in Woebot’s development, the AI team replaced regexes with classifiers \n",
    "trained with supervised learning. The process for creating AI classifiers that \n",
    "comply with regulatory standards was involved—each classifier required months of \n",
    "effort. Typically, a team of internal-data labelers and content creators reviewed \n",
    "examples of user messages (with all personally identifiable information stripped \n",
    "out) taken from a specific point in the conversation. Once the data was placed into\n",
    "categories and labeled, classifiers were trained that could take new input text and\n",
    "place it into one of the existing categories.\n",
    "This process was repeated many times, with the classifier repeatedly evaluated \n",
    "against a test dataset until its performance satisfied us. As a final step, the \n",
    "conversational-management system was updated to “call” these AI classifiers \n",
    "(essentially activating them) and then to route the user to the most appropriate \n",
    "content. For example, if a user wrote that he was feeling angry because he got in a\n",
    "fight with his mom, the system would classify this response as a relationship \n",
    "problem.\n",
    "The technology behind these classifiers is constantly evolving. In the early days, \n",
    "the team used an open-source library for text classification called fastText, \n",
    "sometimes in combination with regular expressions. As AI continued to advance and \n",
    "new models became available, the team was able to train new models on the same \n",
    "labeled data for improvements in both accuracy and recall. For example, when the \n",
    "early transformer model BERT was released in October 2018, the team rigorously \n",
    "evaluated its performance against the fastText version. BERT was superior in both \n",
    "precision and recall for our use cases, and so the team replaced all fastText \n",
    "classifiers with BERT and launched the new models in January 2019. We immediately \n",
    "saw improvements in classification accuracy across the models.\n",
    "An illustration of a robot cheering.EDDIE GUY\n",
    "Woebot and Large Language Models\n",
    "When ChatGPT was released in November 2022, Woebot was more than 5 years old. The \n",
    "AI team faced the question of whether LLMs like ChatGPT could be used to meet \n",
    "Woebot’s design goals and enhance users’ experiences, putting them on a path to \n",
    "better mental health.\n",
    "We were excited by the possibilities, because ChatGPT could carry on fluid and \n",
    "complex conversations about millions of topics, far more than we could ever include\n",
    "in a decision tree. However, we had also heard about troubling examples of chatbots\n",
    "providing responses that were decidedly not supportive, including advice on how to \n",
    "maintain and hide an eating disorder and guidance on methods of self-harm. In one \n",
    "tragic case in Belgium, a grieving widow accused a chatbot of being responsible for\n",
    "her husband’s suicide.\n",
    "The first thing we did was try out ChatGPT ourselves, and we quickly became experts\n",
    "in prompt engineering. For example, we prompted ChatGPT to be supportive and played\n",
    "the roles of different types of users to explore the system’s strengths and \n",
    "shortcomings. We described how we were feeling, explained some problems we were \n",
    "facing, and even explicitly asked for help with depression or anxiety.\n",
    "A few things stood out. First, ChatGPT quickly told us we needed to talk to someone\n",
    "else—a therapist or doctor. ChatGPT isn’t intended for medical use, so this default\n",
    "response was a sensible design decision by the chatbot’s makers. But it wasn’t very\n",
    "satisfying to constantly have our conversation aborted. Second, ChatGPT’s responses\n",
    "were often bulleted lists of encyclopedia-style answers. For example, it would list\n",
    "six actions that could be helpful for depression. We found that these lists of \n",
    "items told the user what to do but didn’t explain how to take these steps. Third, \n",
    "in general, the conversations ended quickly and did not allow a user to engage in \n",
    "the psychological processes of change.\n",
    "It was clear to our team that an off-the-shelf LLM would not deliver the \n",
    "psychological experiences we were after. LLMs are based on reward models that value\n",
    "the delivery of correct answers; they aren’t given incentives to guide a user \n",
    "through the process of discovering those results themselves. Instead of “sitting \n",
    "with open hands,” the models make assumptions about what the user is saying to \n",
    "deliver a response with the highest assigned reward.\n",
    "We had to decide whether generative AI could make Woebot a better tool, or whether \n",
    "the technology was too dangerous to incorporate into our product.\n",
    "To see if LLMs could be used within a mental-health context, we investigated ways \n",
    "of expanding our proprietary conversational-management system. We looked into \n",
    "frameworks and open-source techniques for managing prompts and prompt \n",
    "chains—sequences of prompts that ask an LLM to achieve a task through multiple \n",
    "subtasks. In January of 2023, a platform called LangChain was gaining in popularity\n",
    "and offered techniques for calling multiple LLMs and managing prompt chains. \n",
    "However, LangChain lacked some features that we knew we needed: It didn’t provide a\n",
    "visual user interface like our proprietary system, and it didn’t provide a way to \n",
    "safeguard the interactions with the LLM. We needed a way to protect Woebot users \n",
    "from the common pitfalls of LLMs, including hallucinations (where the LLM says \n",
    "things that are plausible but untrue) and simply straying off topic.\n",
    "Ultimately, we decided to expand our platform by implementing our own LLM \n",
    "prompt-execution engine, which gave us the ability to inject LLMs into certain \n",
    "parts of our existing rules-based system. The engine allows us to support concepts \n",
    "such as prompt chains while also providing integration with our existing \n",
    "conversational routing system and rules. As we developed the engine, we were \n",
    "fortunate to be invited into the beta programs of many new LLMs. Today, our \n",
    "prompt-execution engine can call more than a dozen different LLM models, including \n",
    "variously sized OpenAI models, Microsoft Azure versions of OpenAI models, \n",
    "Anthropic’s Claude, Google Bard (now Gemini), and open-source models running on the\n",
    "Amazon Bedrock platform, such as Meta’s Llama 2. We use this engine exclusively for\n",
    "exploratory research that’s been approved by an institutional review board, or IRB.\n",
    "It took us about three months to develop the infrastructure and tooling support for\n",
    "LLMs. Our platform allows us to package features into different products and \n",
    "experiments, which in turn lets us maintain control over software versions and \n",
    "manage our research efforts while ensuring that our commercially deployed products \n",
    "are unaffected. We’re not using LLMs in any of our products; the LLM-enabled \n",
    "features can be used only in a version of Woebot for exploratory studies.\n",
    "A Trial for an LLM-Augmented Woebot\n",
    "We had some false starts in our development process. We first tried creating an \n",
    "experimental chatbot that was almost entirely powered by generative AI; that is, \n",
    "the chatbot directly used the text responses from the LLM. But we ran into a couple\n",
    "of problems. The first issue was that the LLMs were eager to demonstrate how smart \n",
    "and helpful they are! This eagerness was not always a strength, as it interfered \n",
    "with the user’s own process.\n",
    "For example, the user might be doing a thought-challenging exercise, a common tool \n",
    "in CBT. If the user says, “I’m a bad mom,” a good next step in the exercise could \n",
    "be to ask if the user’s thought is an example of “labeling,” a cognitive distortion\n",
    "where we assign a negative label to ourselves or others. But LLMs were quick to \n",
    "skip ahead and demonstrate how to reframe this thought, saying something like “A \n",
    "kinder way to put this would be, ‘I don’t always make the best choices, but I love \n",
    "my child.’” CBT exercises like thought challenging are most helpful when the person\n",
    "does the work themselves, coming to their own conclusions and gradually changing \n",
    "their patterns of thinking.\n",
    "A second difficulty with LLMs was in style matching. While social media is rife \n",
    "with examples of LLMs responding in a Shakespearean sonnet or a poem in the style \n",
    "of Dr. Seuss, this format flexibility didn’t extend to Woebot’s style. Woebot has a\n",
    "warm tone that has been refined for years by conversational designers and clinical \n",
    "experts. But even with careful instructions and prompts that included examples of \n",
    "Woebot’s tone, LLMs produced responses that didn’t “sound like Woebot,” maybe \n",
    "because a touch of humor was missing, or because the language wasn’t simple and \n",
    "clear.\n",
    "The LLM-augmented Woebot was well-behaved, refusing to take inappropriate actions \n",
    "like diagnosing or offering medical advice.\n",
    "However, LLMs truly shone on an emotional level. When coaxing someone to talk about\n",
    "their joys or challenges, LLMs crafted personalized responses that made people feel\n",
    "understood. Without generative AI, it’s impossible to respond in a novel way to \n",
    "every different situation, and the conversation feels predictably “robotic.”\n",
    "We ultimately built an experimental chatbot that possessed a hybrid of generative \n",
    "AI and traditional NLP-based capabilities. In July 2023 we registered an \n",
    "IRB-approved clinical study to explore the potential of this LLM-Woebot hybrid, \n",
    "looking at satisfaction as well as exploratory outcomes like symptom changes and \n",
    "attitudes toward AI. We feel it’s important to study LLMs within controlled \n",
    "clinical studies due to their scientific rigor and safety protocols, such as \n",
    "adverse event monitoring. Our Build study included U.S. adults above the age of 18 \n",
    "who were fluent in English and who had neither a recent suicide attempt nor current\n",
    "suicidal ideation. The double-blind structure assigned one group of participants \n",
    "the LLM-augmented Woebot while a control group got the standard version; we then \n",
    "assessed user satisfaction after two weeks.\n",
    "We built technical safeguards into the experimental Woebot to ensure that it \n",
    "wouldn’t say anything to users that was distressing or counter to the process. The \n",
    "safeguards tackled the problem on multiple levels. First, we used what engineers \n",
    "consider “best in class” LLMs that are less likely to produce hallucinations or \n",
    "offensive language. Second, our architecture included different validation steps \n",
    "surrounding the LLM; for example, we ensured that Woebot wouldn’t give an \n",
    "LLM-generated response to an off-topic statement or a mention of suicidal ideation \n",
    "(in that case, Woebot provided the phone number for a hotline). Finally, we wrapped\n",
    "users’ statements in our own careful prompts to elicit appropriate responses from \n",
    "the LLM, which Woebot would then convey to users. These prompts included both \n",
    "direct instructions such as “don’t provide medical advice” as well as examples of \n",
    "appropriate responses in challenging situations.\n",
    "While this initial study was short—two weeks isn’t much time when it comes to \n",
    "psychotherapy—the results were encouraging. We found that users in the experimental\n",
    "and control groups expressed about equal satisfaction with Woebot, and both groups \n",
    "had fewer self-reported symptoms. What’s more, the LLM-augmented chatbot was \n",
    "well-behaved, refusing to take inappropriate actions like diagnosing or offering \n",
    "medical advice. It consistently responded appropriately when confronted with \n",
    "difficult topics like body image issues or substance use, with responses that \n",
    "provided empathy without endorsing maladaptive behaviors. With participant consent,\n",
    "we reviewed every transcript in its entirety and found no concerning LLM-generated \n",
    "utterances—no evidence that the LLM hallucinated or drifted off-topic in a \n",
    "problematic way. What’s more, users reported no device-related adverse events.\n",
    "This study was just the first step in our journey to explore what’s possible for \n",
    "future versions of Woebot, and its results have emboldened us to continue testing \n",
    "LLMs in carefully controlled studies. We know from our prior research that Woebot \n",
    "users feel a bond with our bot. We’re excited about LLMs’ potential to add more \n",
    "empathy and personalization, and we think it’s possible to avoid the \n",
    "sometimes-scary pitfalls related to unfettered LLM chatbots.\n",
    "We believe strongly that continued progress within the LLM research community will,\n",
    "over time, transform the way people interact with digital tools like Woebot. Our \n",
    "mission hasn’t changed: We’re committed to creating a world-class solution that \n",
    "helps people along their mental-health journeys. For anyone who wants to talk, we \n",
    "want the best possible version of Woebot to be there for them\n",
    "\n",
    "summary:\n",
    "Artificial intelligence (AI) has played an increasingly important role in medicine, including online scheduling, drug interaction warnings, medical imaging, gastroenterology, surgery, and online consultations. AI can help physicians make quicker and more accurate diagnoses, providing better treatment plans. In radiology, computer-assisted diagnosis (CAD) has been used to detect lesions, compose reports, create differential diagnoses, screen diabetic retin Artificial intelligence (AI) has the potential to greatly improve healthcare, with benefits such as faster diagnosis, improved accuracy in specific cases, and improved regulatory requirements and paperwork. However, concerns have been raised about data accessibility, ethical dilemmas, and accountability when using AI in healthcare. To address these issues, solutions such as developing ethical governance and transparency, implementing strict regulations, performing regular auditing, validating AI systems, and developing easy-to-understand AI education for healthcare workers have been recommended. Proper training for healthcare workers is also important to ensure maximum accuracy in disease screening and treatment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\LocalLLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: The Transformer is a type of neural network architecture that was introduced in a 2017 paper by Vaswani et al. It is designed to process sequential data, such as natural language text, and has achieved state-of-the-art performance on several NLP tasks. The key innovation of the Transformer is its self-attention mechanism, which allows the model to weigh the importance of different words in a sentence when processing it. This enables the model to capture long-range dependencies between words more effectively than traditional recurrent neural networks (RNNs)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAnswer: The Transformer is a type of neural network architecture that was introduced in a 2017 paper by Vaswani et al. It is designed to process sequential data, such as natural language text, and has achieved state-of-the-art performance on several NLP tasks. The key innovation of the Transformer is its self-attention mechanism, which allows the model to weigh the importance of different words in a sentence when processing it. This enables the model to capture long-range dependencies between words more effectively than traditional recurrent neural networks (RNNs).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "sys_prompt: PromptTemplate = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are a AI agent , this the user given question /\n",
    "    {question}. Tell him the corrent answer.\"\"\"\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=sys_prompt)\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
    "llm_chain = LLMChain(prompt=chat_prompt, llm=llm)\n",
    "\n",
    "question = \"What is the Transfomer?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
